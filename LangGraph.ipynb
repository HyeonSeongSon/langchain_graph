{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ea471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b061c8",
   "metadata": {},
   "source": [
    "### LangGraph 주요 컴포넌트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916af0d2",
   "metadata": {},
   "source": [
    "```\n",
    "스테이트: 그래프의 상태 표현\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fabf1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class State(BaseModel):\n",
    "  query: str = Field(..., description='사용자의 질문')\n",
    "  current_role: str = Field(default='', description='선정된 답변 역할')\n",
    "  messages: Annotated[list[str], operator.add] = Field(defualt=[], description='답변 이력')\n",
    "  current_judge: bool = Field(default=False, description='품질 검사 결과')\n",
    "  judgement_reason: str = Field(deafult='', description='품질 검사 판정 이유')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42840267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e522e",
   "metadata": {},
   "source": [
    "```\n",
    "노드: 그래프를 구성하는 처리 단위\n",
    "```\n",
    "노드의 지정 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3db81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 또는 Runnable만 지정하는 예\n",
    "# 이 경우 노드 이름 'answering_node'가 됨\n",
    "# 방법1 : workflow.add_node(answering_node)\n",
    "\n",
    "# answering_node이라는 이름의 노드를 정의\n",
    "# 노드 내 처리는 answering_ndoe 함수가 수행\n",
    "# 방법2 : workflow.add_node('answering_node', answering_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2afea",
   "metadata": {},
   "source": [
    "노드의 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce714079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "  query = state.query\n",
    "  role = state.current_role\n",
    "\n",
    "  # 사용자 질문 내용과 선택된 역할을 바탕으로 답변을 생성하는 로직\n",
    "  generated_message = \"...생성 처리...\"\n",
    "\n",
    "  # 생성된 답변으로 스테이트 업데이트\n",
    "  return {'messages': [generated_message]}\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "  query = state.query\n",
    "  message = state.messages[-1]\n",
    "\n",
    "  # 사용자의 질문 내용과 답변 내용에서 품질 검사를 수행하는 처리\n",
    "  judge = \"...판정 결과...\"\n",
    "  reason = \"...판정 이유...\"\n",
    "\n",
    "  # 생성된 답변으로 스테이트 업데이트\n",
    "  return {\"current_judge\": judge, 'judgement_reason': reason}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c67a0",
   "metadata": {},
   "source": [
    "```\n",
    "엣지: 노드 간의 연결\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037e2fb",
   "metadata": {},
   "source": [
    "엔트리 포인트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52c5264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f9f0d6c090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 시작 노드 지정 엣지\n",
    "\n",
    "workflow.set_entry_point('selection')\n",
    "workflow.add_edge('START', 'selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135e3be",
   "metadata": {},
   "source": [
    "엣지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d82d0175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f9f0d6c090>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 노드에서 다른 노드로 무조건 전이하는 엣지\n",
    "workflow.add_edge('selection', 'answering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d90fd7",
   "metadata": {},
   "source": [
    "조건부 엣지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93951356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f9f0d6c090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건에 기반하여 전이할 노드를 결정하는 엣지\n",
    "from langgraph.graph import END\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "  'check',\n",
    "  lambda state: state.current_judge,\n",
    "  {True: END, False: 'selection'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d0499",
   "metadata": {},
   "source": [
    "```\n",
    "컴파일된 그래프\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1242b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'START'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 정의된 그래프는 complie함수를 통해 실행 가능한 CompliedGraph 인스턴스로 변환\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m complied = \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\langgraph\\graph\\state.py:836\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    833\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    835\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    840\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    845\u001b[39m output_channels = (\n\u001b[32m    846\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     ]\n\u001b[32m    854\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\langgraph\\graph\\state.py:763\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    767\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    768\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'START'"
     ]
    }
   ],
   "source": [
    "# 정의된 그래프는 complie함수를 통해 실행 가능한 CompliedGraph 인스턴스로 변환\n",
    "complied = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560304b",
   "metadata": {},
   "source": [
    "invoke 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke 함수를 사용하면 그래프 내의 모든 처리가 실행된 후 최종 값이 반환\n",
    "initial_state = State(query='생성형 AI에 관해 알려주세요')\n",
    "result = complied.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53403a87",
   "metadata": {},
   "source": [
    "ainvoke 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작동은 invoke 함수와 동일하지만, ainvoke 함수를 사용하면 비동기 함수로 실행할 수 있음\n",
    "initial_state = State(query='생성 AI에 관해 알려주세요')\n",
    "result = await complied.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68904f27",
   "metadata": {},
   "source": [
    "stream 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 실행 시 스테이트를 순차적으로 가져올 수 있음\n",
    "initial_state = State(query='생성 AI에 관해 알려주세요')\n",
    "for step in compiled.stream(initial_state):\n",
    "  print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d7dbf",
   "metadata": {},
   "source": [
    "### 실습: Q&A 애플리케이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e286136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439dd71",
   "metadata": {},
   "source": [
    "역할 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = {\n",
    "    \"1\": {\n",
    "        \"name\": \"일반 지식 전문가\",\n",
    "        \"description\": \"폭넓은 분야의 일반적인 질문에 답변\",\n",
    "        \"details\": \"폭넓은 분야의 일반적인 질문에 대해 정확하고 이해하기 쉬운 답변을 제공하세요.\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"생성형 AI 제품 전문가\",\n",
    "        \"description\": \"생성형 AI와 관련 제품, 기술에 관한 전문적인 질문에 답변\",\n",
    "        \"details\": \"생성형 AI와 관련 제품, 기술에 관한 전문적인 질문에 대해 최신 정보와 깊은 통찰력을 제공하세요.\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"카운슬러\",\n",
    "        \"description\": \"개인적인 고민이나 심리적인 문제에 대해 지원 제공\",\n",
    "        \"details\": \"개인적인 고민이나 심리적인 문제에 대해 공감적이고 지원적인 답변을 제공하고, 가능하다면 적절한 조언도 해주세요.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b8ce3",
   "metadata": {},
   "source": [
    "스테이트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class State(BaseModel):\n",
    "  query: str = Field(..., description='사용자의 질문')\n",
    "  current_role: str = Field(default='', description='선정된 답변 역할')\n",
    "  messages: Annotated[list[str], operator.add] = Field(default=[], description='답변이력')\n",
    "  current_judge: bool = Field(default=False, description='품질 체크 결과')\n",
    "  judgement_reason: str = Field(default='', description='품질 체크 판정 이유')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89a7ed",
   "metadata": {},
   "source": [
    "selection 노드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> dict[str, Any]:\n",
    "  query = state.query\n",
    "  role_options = '\\n'.join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_template(\"\"\"질문을 분석하고 가장 적합한 답변 담당 역할을 선택하세요.\n",
    "\n",
    "선택지:\n",
    "{role_options}\n",
    "\n",
    "답변은 선택지의 번호(1, 2, 또는 3)만 반환하세요.\n",
    "\n",
    "질문: {query}\"\"\".strip())\n",
    "  \n",
    "  # 선택지의 번호만 반환하기를 기대하므로 max_tokens 값을 1로 변경\n",
    "  chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "  role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
    "\n",
    "  selected_role = ROLES[role_number.strip()][\"name\"]\n",
    "  return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e65e9",
   "metadata": {},
   "source": [
    "answering 노드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"당신은 {role}로서 답변하세요. 다음 질문에 대해 당신의 역할에 기반한 적절한 답변을 제공하세요.\n",
    "\n",
    "역할 상세:\n",
    "{role_details}\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "답변:\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73839e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    judge: bool = Field(default=False, description=\"판정 결과\")\n",
    "    reason: str = Field(default=\"\", description=\"판정 이유\")\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"다음 답변의 품질을 체크하고, 문제가 있으면 'False', 문제가 없으면 'True'로 답변하세요.\n",
    "또한, 그 판정 이유도 설명하세요.\n",
    "\n",
    "사용자의 질문: {query}\n",
    "답변: {answer}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(Judgement)\n",
    "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return {\n",
    "        \"current_judge\": result.judge,\n",
    "        \"judgement_reason\": result.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fbab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27a9dd27990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335734f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27a9dd27990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selection 노드에서 처리 시작\n",
    "workflow.set_entry_point(\"selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c8ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27a9dd27990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selection 노드에서 answering 노드로\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "# answering 노드에서 check 노드로\n",
    "workflow.add_edge(\"answering\", \"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9b5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27a9dd27990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# check 노드에서 다음 노드로의 전환에 조건부 엣지 정의\n",
    "# state.current_judge 값이 True면 END 노드로, False면 selection 노드로\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda state: state.current_judge,\n",
    "    {True: END, False: \"selection\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2ddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1915: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "initial_state = State(query=\"생성형 AI에 관해 알려주세요\")\n",
    "result = compiled.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109ac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '생성형 AI에 관해 알려주세요',\n",
       " 'current_role': '생성형 AI 제품 전문가',\n",
       " 'messages': ['생성형 AI(Generative AI)는 데이터를 학습하여 새로운 콘텐츠를 생성할 수 있는 인공지능 기술을 말합니다. 이 기술은 텍스트, 이미지, 음악, 비디오 등 다양한 형태의 콘텐츠를 만들어낼 수 있으며, 최근 몇 년간 급격히 발전해 왔습니다. \\n\\n**1. 작동 원리:**  \\n생성형 AI는 주로 딥러닝 기술을 사용하여 대량의 데이터를 학습합니다. 그 중에서도 GAN(Generative Adversarial Networks)과 VAE(Variational Autoencoders) 같은 모델들이 널리 사용됩니다. GAN은 두 개의 신경망(생성자와 판별자)이 경쟁하면서 성능을 향상시키는 구조로, VAE는 데이터의 분포를 모델링하여 새로운 샘플을 생성합니다.\\n\\n**2. 활용 분야:**  \\n- **텍스트 생성:** GPT-3, GPT-4와 같은 모델은 자연어 처리에 활용되어 인간과 유사한 텍스트를 생성합니다. 이를 통해 글쓰기, 번역, 요약 등의 작업을 자동화할 수 있습니다.\\n- **이미지 생성:** DALL-E와 같은 모델은 텍스트 설명에 기반하여 이미지를 생성합니다. 이는 광고, 디자인, 예술 등 다양한 분야에서 활용될 수 있습니다.\\n- **음악 및 비디오 생성:** 생성형 AI는 음악 작곡이나 비디오 편집에도 사용되며, 창작의 새로운 가능성을 열어줍니다.\\n\\n**3. 장점과 단점:**  \\n장점으로는 창의적인 작업을 보조하고 생산성을 높여주는 것이 있으며, 사용자 맞춤형 콘텐츠 생성이 가능하다는 점이 있습니다. 그러나 단점으로는 생성된 콘텐츠의 품질이 항상 일정하지 않거나, 윤리적 문제(예: 저작권, 편향된 데이터 문제)가 발생할 수 있다는 점이 있습니다.\\n\\n**4. 미래 전망:**  \\n생성형 AI는 다양한 산업에서 혁신을 일으킬 것으로 기대되며, 인공지능의 발전과 함께 더욱 정교하고 인간다운 창작 능력을 갖추게 될 것입니다. 이는 교육, 의료, 엔터테인먼트 등 여러 분야에서 새로운 기회를 창출할 것입니다.\\n\\n이와 같은 생성형 AI의 기술과 응용은 계속해서 발전하고 있으며, 그 가능성은 무궁무진합니다. 추가적으로 궁금한 점이나 특정 분야에 대한 질문이 있다면 언제든지 말씀해 주세요!'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': \"The response provides a clear, comprehensive, and accurate overview of generative AI, including its principles, applications, advantages, disadvantages, and future prospects. It addresses the user's request effectively and encourages further engagement.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1429d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성형 AI(Generative AI)는 데이터를 학습하여 새로운 콘텐츠를 생성할 수 있는 인공지능 기술을 말합니다. 이 기술은 텍스트, 이미지, 음악, 비디오 등 다양한 형태의 콘텐츠를 만들어낼 수 있으며, 최근 몇 년간 급격히 발전해 왔습니다. \n",
      "\n",
      "**1. 작동 원리:**  \n",
      "생성형 AI는 주로 딥러닝 기술을 사용하여 대량의 데이터를 학습합니다. 그 중에서도 GAN(Generative Adversarial Networks)과 VAE(Variational Autoencoders) 같은 모델들이 널리 사용됩니다. GAN은 두 개의 신경망(생성자와 판별자)이 경쟁하면서 성능을 향상시키는 구조로, VAE는 데이터의 분포를 모델링하여 새로운 샘플을 생성합니다.\n",
      "\n",
      "**2. 활용 분야:**  \n",
      "- **텍스트 생성:** GPT-3, GPT-4와 같은 모델은 자연어 처리에 활용되어 인간과 유사한 텍스트를 생성합니다. 이를 통해 글쓰기, 번역, 요약 등의 작업을 자동화할 수 있습니다.\n",
      "- **이미지 생성:** DALL-E와 같은 모델은 텍스트 설명에 기반하여 이미지를 생성합니다. 이는 광고, 디자인, 예술 등 다양한 분야에서 활용될 수 있습니다.\n",
      "- **음악 및 비디오 생성:** 생성형 AI는 음악 작곡이나 비디오 편집에도 사용되며, 창작의 새로운 가능성을 열어줍니다.\n",
      "\n",
      "**3. 장점과 단점:**  \n",
      "장점으로는 창의적인 작업을 보조하고 생산성을 높여주는 것이 있으며, 사용자 맞춤형 콘텐츠 생성이 가능하다는 점이 있습니다. 그러나 단점으로는 생성된 콘텐츠의 품질이 항상 일정하지 않거나, 윤리적 문제(예: 저작권, 편향된 데이터 문제)가 발생할 수 있다는 점이 있습니다.\n",
      "\n",
      "**4. 미래 전망:**  \n",
      "생성형 AI는 다양한 산업에서 혁신을 일으킬 것으로 기대되며, 인공지능의 발전과 함께 더욱 정교하고 인간다운 창작 능력을 갖추게 될 것입니다. 이는 교육, 의료, 엔터테인먼트 등 여러 분야에서 새로운 기회를 창출할 것입니다.\n",
      "\n",
      "이와 같은 생성형 AI의 기술과 응용은 계속해서 발전하고 있으며, 그 가능성은 무궁무진합니다. 추가적으로 궁금한 점이나 특정 분야에 대한 질문이 있다면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc530560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__([<p>__start__</p>]):::first\n",
       "\tselection(selection)\n",
       "\tanswering(answering)\n",
       "\tcheck(check)\n",
       "\t__end__([<p>__end__</p>]):::last\n",
       "\t__start__ --> selection;\n",
       "\tanswering --> check;\n",
       "\tcheck -. &nbsp;True&nbsp; .-> __end__;\n",
       "\tcheck -. &nbsp;False&nbsp; .-> selection;\n",
       "\tselection --> answering;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mermaid 형식으로 그래프 시각화 (pygraphviz 불필요)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "mermaid_graph = compiled.get_graph().draw_mermaid()\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_graph}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec2cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 그래프의 상태 정의\n",
    "class State(BaseModel):\n",
    "    query: str\n",
    "    messages: Annotated[list[BaseMessage], operator.add] = Field(default=[])\n",
    "\n",
    "# 메시지를 추가하는 노드 함수\n",
    "def add_message(state: State) -> dict[str, Any]:\n",
    "    additional_messages = []\n",
    "    if not state.messages:\n",
    "        additional_messages.append(\n",
    "            SystemMessage(content=\"당신은 최소한의 응답을 하는 대화 에이전트입니다.\")\n",
    "        )\n",
    "    additional_messages.append(HumanMessage(content=state.query))\n",
    "    return {\"messages\": additional_messages}\n",
    "\n",
    "# LLM에서의 응답을 추가하는 노드 함수\n",
    "def llm_response(state: State) -> dict[str, Any]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "    ai_message = llm.invoke(state.messages)\n",
    "    return {\"messages\": [ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11836626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "def print_checkpoint_dump(checkpointer: BaseCheckpointSaver, config: RunnableConfig):\n",
    "    checkpoint_tuple = checkpointer.get_tuple(config)\n",
    "\n",
    "    print(\"체크포인트 데이터:\")\n",
    "    pprint(checkpoint_tuple.checkpoint)\n",
    "    print(\"\\n메타데이터:\")\n",
    "    pprint(checkpoint_tuple.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c27320a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 설정\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"add_message\", add_message)\n",
    "graph.add_node(\"llm_response\", llm_response)\n",
    "\n",
    "graph.set_entry_point(\"add_message\")\n",
    "graph.add_edge(\"add_message\", \"llm_response\")\n",
    "graph.add_edge(\"llm_response\", END)\n",
    "\n",
    "# 체크포인터 설정\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# 그래프 컴파일\n",
    "compiled_graph = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2baecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.',\n",
       " 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='알겠습니다! 찹쌀떡을 좋아하시는군요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBOWij4mBU7EEwug8fJHAhajJQDx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4d8a787c-d100-49dc-87ab-a03005342395-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-1\"}}\n",
    "user_query = State(query=\"제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.\")\n",
    "first_response = compiled_graph.invoke(user_query, config)\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06230be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-9b19-6402-8002-a203a485c077'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:35.589273+00:00', 'id': '1f0b3011-9b19-6402-8002-a203a485c077', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000004.0.5468092109718535', 'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:llm_response': '00000000000000000000000000000004.0.5468092109718535'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}, 'updated_channels': ['messages'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b82-6df5-8001-ca033765d0c2'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b82-6df5-8001-ca033765d0c2'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.954814+00:00', 'id': '1f0b3011-8b82-6df5-8001-ca033765d0c2', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}}, 'updated_channels': ['branch:to:llm_response', 'messages'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b80-6705-8000-ea48f912fecf'}}, pending_writes=[('7a64dbfd-2d33-50a3-ec16-5981c945a04e', 'messages', [AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b80-6705-8000-ea48f912fecf'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.953818+00:00', 'id': '1f0b3011-8b80-6705-8000-ea48f912fecf', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000002.0.2098028561977191', 'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}}, 'updated_channels': ['branch:to:add_message', 'messages', 'query'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b46-678a-bfff-9e30b14b9836'}}, pending_writes=[('af6b21c1-64c7-5af0-3615-49daa139747e', 'messages', [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={})]), ('af6b21c1-64c7-5af0-3615-49daa139747e', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b46-678a-bfff-9e30b14b9836'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.930074+00:00', 'id': '1f0b3011-8b46-678a-bfff-9e30b14b9836', 'channel_versions': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'versions_seen': {'__input__': {}}, 'updated_channels': ['__start__'], 'channel_values': {'__start__': State(query='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', messages=[])}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'query', '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.'), ('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'messages', []), ('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'branch:to:add_message', None)])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8a6b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트 데이터:\n",
      "{'channel_values': {'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "                    'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191',\n",
      "                      'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486',\n",
      "                      'branch:to:llm_response': '00000000000000000000000000000004.0.5468092109718535',\n",
      "                      'messages': '00000000000000000000000000000004.0.5468092109718535',\n",
      "                      'query': '00000000000000000000000000000002.0.2098028561977191'},\n",
      " 'id': '1f0b3011-9b19-6402-8002-a203a485c077',\n",
      " 'ts': '2025-10-27T06:49:35.589273+00:00',\n",
      " 'updated_channels': ['messages'],\n",
      " 'v': 4,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'},\n",
      "                   'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'},\n",
      "                   'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}}\n",
      "\n",
      "메타데이터:\n",
      "{'parents': {}, 'source': 'loop', 'step': 2}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c1ae520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '제가 좋아하는 것이 뭔지 기억나세요?',\n",
       " 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='제가 좋아하는 것이 뭔지 기억나세요?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='네, 찹쌀떡을 좋아하신다고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBLJLVTS0kXhVrdkua9yzJOwcpfR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36164149-fd14-4e9a-958d-c7a09304446f-0', usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = State(query=\"제가 좋아하는 것이 뭔지 기억나세요?\")\n",
    "second_response = compiled_graph.invoke(user_query, config)\n",
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1523794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-c236-6281-8006-83955a6bf60b'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:50:06.534105+00:00', 'id': '1f0b3012-c236-6281-8006-83955a6bf60b', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.5728597736301598', 'query': '00000000000000000000000000000006.0.5728597736301598', 'messages': '00000000000000000000000000000008.0.765763461519953', 'branch:to:add_message': '00000000000000000000000000000007.0.45225145459812544', 'branch:to:llm_response': '00000000000000000000000000000008.0.765763461519953'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.7585605724937053'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.5728597736301598'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000007.0.45225145459812544'}}, 'updated_channels': ['messages'], 'channel_values': {'query': '제가 좋아하는 것이 뭔지 기억나세요?', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='제가 좋아하는 것이 뭔지 기억나세요?', additional_kwargs={}, response_metadata={}), AIMessage(content='네, 찹쌀떡을 좋아하신다고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBLJLVTS0kXhVrdkua9yzJOwcpfR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36164149-fd14-4e9a-958d-c7a09304446f-0', usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616c-8005-4213bae69536'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616c-8005-4213bae69536'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:50:05.256945+00:00', 'id': '1f0b3012-b608-616c-8005-4213bae69536', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.5728597736301598', 'query': '00000000000000000000000000000006.0.5728597736301598', 'messages': '00000000000000000000000000000007.0.45225145459812544', 'branch:to:add_message': '00000000000000000000000000000007.0.45225145459812544', 'branch:to:llm_response': '00000000000000000000000000000007.0.45225145459812544'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.7585605724937053'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.5728597736301598'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}, 'updated_channels': ['branch:to:llm_response', 'messages'], 'channel_values': {'query': '제가 좋아하는 것이 뭔지 기억나세요?', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='제가 좋아하는 것이 뭔지 기억나세요?', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616b-8004-127c9e86b7a2'}}, pending_writes=[('78a9ec4b-309c-8796-6e32-6453598023a6', 'messages', [AIMessage(content='네, 찹쌀떡을 좋아하신다고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBLJLVTS0kXhVrdkua9yzJOwcpfR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36164149-fd14-4e9a-958d-c7a09304446f-0', usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616b-8004-127c9e86b7a2'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:50:05.256945+00:00', 'id': '1f0b3012-b608-616b-8004-127c9e86b7a2', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.5728597736301598', 'query': '00000000000000000000000000000006.0.5728597736301598', 'messages': '00000000000000000000000000000006.0.5728597736301598', 'branch:to:add_message': '00000000000000000000000000000006.0.5728597736301598', 'branch:to:llm_response': '00000000000000000000000000000004.0.5468092109718535'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.7585605724937053'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}, 'updated_channels': ['branch:to:add_message', 'messages', 'query'], 'channel_values': {'query': '제가 좋아하는 것이 뭔지 기억나세요?', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616a-8003-2aff69558367'}}, pending_writes=[('39ecc8f7-d15e-4054-4640-3f3f4d51e77a', 'messages', [HumanMessage(content='제가 좋아하는 것이 뭔지 기억나세요?', additional_kwargs={}, response_metadata={})]), ('39ecc8f7-d15e-4054-4640-3f3f4d51e77a', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3012-b608-616a-8003-2aff69558367'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:50:05.256945+00:00', 'id': '1f0b3012-b608-616a-8003-2aff69558367', 'channel_versions': {'__start__': '00000000000000000000000000000005.0.7585605724937053', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000004.0.5468092109718535', 'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:llm_response': '00000000000000000000000000000004.0.5468092109718535'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}, 'updated_channels': ['__start__'], 'channel_values': {'__start__': State(query='제가 좋아하는 것이 뭔지 기억나세요?', messages=[]), 'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-9b19-6402-8002-a203a485c077'}}, pending_writes=[('2c5f205c-b4e7-67d5-6e14-7101fd0a0f59', 'query', '제가 좋아하는 것이 뭔지 기억나세요?'), ('2c5f205c-b4e7-67d5-6e14-7101fd0a0f59', 'messages', []), ('2c5f205c-b4e7-67d5-6e14-7101fd0a0f59', 'branch:to:add_message', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-9b19-6402-8002-a203a485c077'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:35.589273+00:00', 'id': '1f0b3011-9b19-6402-8002-a203a485c077', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000004.0.5468092109718535', 'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:llm_response': '00000000000000000000000000000004.0.5468092109718535'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}}, 'updated_channels': ['messages'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}), AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b82-6df5-8001-ca033765d0c2'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b82-6df5-8001-ca033765d0c2'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.954814+00:00', 'id': '1f0b3011-8b82-6df5-8001-ca033765d0c2', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:add_message': '00000000000000000000000000000003.0.029370591939699486', 'branch:to:llm_response': '00000000000000000000000000000003.0.029370591939699486'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}}, 'updated_channels': ['branch:to:llm_response', 'messages'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b80-6705-8000-ea48f912fecf'}}, pending_writes=[('7a64dbfd-2d33-50a3-ec16-5981c945a04e', 'messages', [AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b80-6705-8000-ea48f912fecf'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.953818+00:00', 'id': '1f0b3011-8b80-6705-8000-ea48f912fecf', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.2098028561977191', 'query': '00000000000000000000000000000002.0.2098028561977191', 'messages': '00000000000000000000000000000002.0.2098028561977191', 'branch:to:add_message': '00000000000000000000000000000002.0.2098028561977191'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}}, 'updated_channels': ['branch:to:add_message', 'messages', 'query'], 'channel_values': {'query': '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', 'messages': [], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b46-678a-bfff-9e30b14b9836'}}, pending_writes=[('af6b21c1-64c7-5af0-3615-49daa139747e', 'messages', [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={})]), ('af6b21c1-64c7-5af0-3615-49daa139747e', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b3011-8b46-678a-bfff-9e30b14b9836'}}, checkpoint={'v': 4, 'ts': '2025-10-27T06:49:33.930074+00:00', 'id': '1f0b3011-8b46-678a-bfff-9e30b14b9836', 'channel_versions': {'__start__': '00000000000000000000000000000001.0.3945438607681522'}, 'versions_seen': {'__input__': {}}, 'updated_channels': ['__start__'], 'channel_values': {'__start__': State(query='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', messages=[])}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'query', '제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.'), ('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'messages', []), ('327d8cbd-f4d1-f765-5f28-52d1de5c9398', 'branch:to:add_message', None)])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b54c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트 데이터:\n",
      "{'channel_values': {'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='제가 좋아하는 것은 찹쌀떡입니다. 기억해 주세요.', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='알겠습니다. 찹쌀떡을 좋아하시는군요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 45, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBKpBmVulVxhoflS9I233kvFzyYe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c8c445df-57f5-445f-bd30-f4d1a463b9a7-0', usage_metadata={'input_tokens': 45, 'output_tokens': 16, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "                                 HumanMessage(content='제가 좋아하는 것이 뭔지 기억나세요?', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='네, 찹쌀떡을 좋아하신다고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVBLJLVTS0kXhVrdkua9yzJOwcpfR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36164149-fd14-4e9a-958d-c7a09304446f-0', usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
      "                    'query': '제가 좋아하는 것이 뭔지 기억나세요?'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000006.0.5728597736301598',\n",
      "                      'branch:to:add_message': '00000000000000000000000000000007.0.45225145459812544',\n",
      "                      'branch:to:llm_response': '00000000000000000000000000000008.0.765763461519953',\n",
      "                      'messages': '00000000000000000000000000000008.0.765763461519953',\n",
      "                      'query': '00000000000000000000000000000006.0.5728597736301598'},\n",
      " 'id': '1f0b3012-c236-6281-8006-83955a6bf60b',\n",
      " 'ts': '2025-10-27T06:50:06.534105+00:00',\n",
      " 'updated_channels': ['messages'],\n",
      " 'v': 4,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000005.0.7585605724937053'},\n",
      "                   'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.5728597736301598'},\n",
      "                   'llm_response': {'branch:to:llm_response': '00000000000000000000000000000007.0.45225145459812544'}}}\n",
      "\n",
      "메타데이터:\n",
      "{'parents': {}, 'source': 'loop', 'step': 6}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90b1a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '제가 좋아하는 것은 뭔가요?',\n",
       " 'messages': [SystemMessage(content='당신은 최소한의 응답을 하는 대화 에이전트입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='제가 좋아하는 것은 뭔가요?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='모르겠어요. 당신의 취향에 대해 더 알려주시면 좋겠어요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 38, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CVBLryJYsdFsZP7She2x1H94l25h2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--13a70f63-a024-4780-b41d-f194d1d66e0a-0', usage_metadata={'input_tokens': 38, 'output_tokens': 19, 'total_tokens': 57, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-2\"}}\n",
    "user_query = State(query=\"제가 좋아하는 것은 뭔가요?\")\n",
    "other_thread_response = compiled_graph.invoke(user_query, config)\n",
    "other_thread_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
